# `rna-seek run` 

## 1. About 
The `rna-seek` executable is composed of several inter-related sub commands. Please see `rna-seek -h` for all available options.

This part of the documentation describes options and concepts for <code>rna-seek <b>run</b></code> sub command in more detail. With minimal configuration, the **`run`** sub command enables you to start running RNA-seek pipeline. 

Setting up the RNA-seek pipeline is fast and easy! In its most basic form, <code>rna-seek <b>run</b></code> only has *three required inputs*.

## 2. Synopsis
```text
$ ./rna-seek run [-h] --input INPUT [INPUT ...] \
                      --output OUTPUT \
                      --genome {hg38_30, mm10_M21} \
                      [--mode {local, slurm}] \
                      [--dry-run] \
                      [--star-2-pass-basic] \
                      [--threads THREADS] \
                      [--singularity-cache SINGULARITY_CACHE] \
                      [--sif-cache SIF_CACHE] 
```

The synopsis for each command shows its parameters and their usage. Optional parameters are shown in square brackets.

A user **must** provide a list of FastQ files (globbing is supported) to analyze via `--input` argument, an output directory to store results via `--output` argument and select reference genome for alignment and annotation via the `--genome` argument. 

Use you can always use the `-h` option for information on a specific command. 



### 2.1 Required Arguments

Each of the following arguments are required. Failure to provide a required argument will result in a non-zero exit-code.

  `--input INPUT [INPUT ...]`  
> **Input FastQ file(s) to process.**  
> *type: string*  
> 
> One or more FastQ files can be provided. From the command-line, each FastQ file should seperated by a space. Globbing is supported! This makes selecting FastQ files easier. Input FastQ files should be gzipp-ed. The pipeline supports single-end and pair-end RNA-seq data; however, the pipeline will not process a mixture of single-end and paired-end samples together. If you have a mixture of single-end and pair-end samples to process, please process them as two seperate instances of the RNA-seek pipeline (with two seperate output directories).   
> 
> ***Example:*** `--input .tests/*.R?.fastq.gz`


  `--output OUTPUT`
> **Path to an output directory.**   
> *type: string*
>   
> This location is where the pipeline will create all of its output files, also known as the pipeline's working directory. If the provided output directory does not exist, it will be initialized automatically.
> 
> ***Example:*** `--output /scratch/$USER/RNA_hg38`


  `--genome {hg38_30,mm10_M21,custom.json}`
> **Reference genome.**   
> *type: string*
>   
> This option defines the reference genome for your set of samples. On Biowulf, RNA-seek does comes bundled with pre built reference files for human and mouse samples; however, it is worth noting that the pipeline does accept a custom reference genome built with the build sub command. Building a new reference genome is easy! You can create a custom reference genome with a single command. This is extremely useful when working with non-model organisms. New users can reference the documentation's [getting started](../TLDR-RNA-seq/#3-building-reference-files) section to see how a reference genome is built. 
>
> ***Pre built Option***  
> Here is a list of available pre built genomes on Biowulf: hg38_30 or mm10_M21. Please see the [resources page](../RNA-seq//Resources/#1-reference-genomes) for more information about each pre built option.
>
> ***Custom Option***   
> A user can also supply a custom reference genome built with the build sub command. Please supply the custom reference JSON file that was generated by the build sub command. The name of this custom reference JSON file is dependent on the values provided to the following *rna-seek build* args, `--ref-name REF_NAME` and `--gtf-ver GTF_VER`, where the name of the provided custom reference JSON file would be: `{REF_NAME}_{GTF_VER}.json`.
>   
> ***Example:*** `--genome hg38_30` *OR* `--genome /scratch/${USER}/hg38_36/hg38_36.json`  

### 2.2 Options

Each of the following arguments are optional and do not need to be provided. 

  `-h, --help`            
> **Display Help.**  
> *type: boolean*
> 
> Shows command's synopsis, help message, and an example command
> 
> ***Example:*** `--help`


  `--dry-run`            
> **Dry run the pipeline.**  
> *type: boolean*
> 
> Displays what steps in the pipeline remain or will be run. Does not execute anything!
>
> ***Example:*** `--dry-run`


  `--mode {local,slurm}`  
> **Execution Method.**</h3>  
> *type: boolean*  
> *default: local*
> 
> Execution Method. Defines the mode or method of execution. Vaild mode options include: local or slurm. 
> 
> ***local***  
> Local executions will run serially on compute instance. This is useful for testing, debugging, or when a users does not have access to a high performance computing environment. If this option is not provided, it will default to a local execution mode. 
> 
> ***slurm***    
> The slurm execution method will submit jobs to a cluster using a singularity backend. It is recommended running RNA-seek in this mode as execution will be significantly faster in a distributed environment.
> 
> ***Example:*** `--mode slurm`


  `--star-2-pass-basic`  
> **Run STAR in per sample 2-pass mapping mode.**  
> *type: boolean*
> 
> It is recommended to use this option when processing a set of unrelated samples or when processing samples in a clinical setting. It is not adivsed to use this option for a study with multiple related samples. 
> 
> By default, the pipeline ultilizes a multi sample 2-pass mapping approach where the set of splice junctions detected across all samples are provided to the second pass of STAR. This option overrides the default behavior so each sample will be processed in a per sample two-pass basic mode.
> 
> ***Example:*** `--star-2-pass-basic`
  

  `--threads THREADS`   
> **Max number of threads for each process.**  
> *type: int*  
> *default: 2*
> 
> Max number of threads for each process. This option is more applicable when running the pipeline with `--mode local`.  It is recommended setting this vaule to the maximum number of CPUs available on the host machine.
> 
> ***Example:*** `--threads 12`


  `--singularity-cache SINGULARITY_CACHE`  
> **Overrides the $SINGULARITY_CACHEDIR environment variable.**  
> *type: string*  
> *default: `--output OUTPUT/.singularity`*
>
> Singularity will cache image layers pulled from remote registries. This ultimately speeds up the process of pull an image from DockerHub if an image layer already exists in the singularity cache directory. By default, the cache is set to the value provided to the `--output` argument. Please note that this cache cannot be shared across users. Singularity strictly enforces you own the cache directory and will return a non-zero exit code if you do not own the cache directory! See the `--sif-cache` option to create a shareable resource. 
> 
> ***Example:*** `--singularity-cache /data/$USER/.singularity`


  `--sif-cache SIF_CACHE`
> **Path where a local cache of SIFs are stored.**  
> *type: string*  
>
> Uses a local cache of SIFs on the filesystem. This SIF cache can be shared across users if permissions are set correctly. If a SIF does not exist in the SIF cache, the image will be pulled from Dockerhub and a warning message will be displayed. The `rna-seek cache` subcommand can be used to create a local SIF cache. Please see `rna-seek cache` for more information. This command is extremely useful for avoiding DockerHub pull rate limits. It also remove any potential errors that could occur due to network issues or DockerHub being temporarily unavailable. We recommend running RNA-seek with this option when ever possible.
> 
> ***Example:*** `--singularity-cache /data/$USER/SIFs`



## 3. Example
```bash 
# Step 0.) Grab an interactive node (do not run on head node)
srun -N 1 -n 1 --time=12:00:00 -p interactive --mem=8gb  --cpus-per-task=4 --pty bash
module purge
module load singularity snakemake

# Step 1.) Dry run pipeline with provided test data
./rna-seek run --input .tests/*.R?.fastq.gz \
               --output /scratch/$USER/RNA_hg38 \
               --genome hg38_30 \
               --mode slurm \
               --star-2-pass-basic \
               --dry-run

# Step 2.) Run RNA-seek pipeline
# The slurm mode will submit jobs to the cluster.
# It is recommended running rna-seek in this mode.
./rna-seek run --input .tests/*.R?.fastq.gz \
               --output /scratch/$USER/RNA_hg38 \
               --genome hg38_30 \
               --mode slurm \
               --star-2-pass-basic
```

